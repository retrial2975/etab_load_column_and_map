import streamlit as st
import pandas as pd
import plotly.express as px

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏ï‡πá‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á
st.set_page_config(layout="wide")

# --- Function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á DataFrame ‡πÄ‡∏õ‡πá‡∏ô CSV ---
@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Combination (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
def calculate_combinations(df_forces_filtered):
    value_cols = ['P', 'V2', 'V3', 'T', 'M2', 'M3']
    group_cols = ['Story', 'Column', 'Unique Name', 'Station']
    pivot_df = df_forces_filtered.pivot_table(index=group_cols, columns='Output Case', values=value_cols, fill_value=0)
    pivot_df.columns = ['_'.join(map(str, col)).strip() for col in pivot_df.columns.values]
    pivot_df.reset_index(inplace=True)
    required_cases = ['Dead', 'Live', 'SDL', 'EX', 'EY']
    for case in required_cases:
        for val in value_cols:
            col_name = f'{val}_{case}'
            if col_name not in pivot_df.columns:
                pivot_df[col_name] = 0
    combinations = {
        'U01': {'Dead': 1.4, 'SDL': 1.4, 'Live': 1.7}, 'U02': {'Dead': 1.05, 'SDL': 1.05, 'Live': 1.275, 'EX': 1},
        'U03': {'Dead': 1.05, 'SDL': 1.05, 'Live': 1.275, 'EX': -1}, 'U04': {'Dead': 1.05, 'SDL': 1.05, 'Live': 1.275, 'EY': 1},
        'U05': {'Dead': 1.05, 'SDL': 1.05, 'Live': 1.275, 'EY': -1}, 'U06': {'Dead': 0.9, 'SDL': 0.9, 'EX': 1},
        'U07': {'Dead': 0.9, 'SDL': 0.9, 'EX': -1}, 'U08': {'Dead': 0.9, 'SDL': 0.9, 'EY': 1},
        'U09': {'Dead': 0.9, 'SDL': 0.9, 'EY': -1},
    }
    combo_dfs = []
    for name, factors in combinations.items():
        temp_df = pivot_df[group_cols].copy()
        formula_parts = [f"{v:+g}{k}" for k, v in factors.items()]
        formula_string = "".join(formula_parts).lstrip('+')
        temp_df['Output Case'] = f"{name}: {formula_string}"
        for val_col in value_cols:
            total_val = sum(pivot_df.get(f'{val_col}_{case}', 0) * factor * (2.5 if val_col in ['V2', 'V3'] and case in ['EX', 'EY'] else 1) for case, factor in factors.items())
            temp_df[val_col] = total_val
        combo_dfs.append(temp_df)
    return pd.concat(combo_dfs, ignore_index=True)

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å (Function) ---
@st.cache_data
def process_excel_data(uploaded_excel_file):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel
    ‡∏à‡∏∞ return ‡∏Ñ‡πà‡∏≤ 3 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏∑‡∏≠:
    1. df_final: DataFrame ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô)
    2. df_forces_filtered: DataFrame ‡∏î‡∏¥‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô
    3. df_merged_coords: DataFrame ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ã‡πâ‡∏≥
    """
    try:
        df_forces = pd.read_excel(uploaded_excel_file, sheet_name='Element Forces - Columns', header=1).drop(0).reset_index(drop=True)
        df_connectivity = pd.read_excel(uploaded_excel_file, sheet_name='Column Object Connectivity', header=1).drop(0).reset_index(drop=True)
        df_points = pd.read_excel(uploaded_excel_file, sheet_name='Point Object Connectivity', header=1).drop(0).reset_index(drop=True)
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏µ‡∏ó‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel: {e}")
        return None, None, None

    # --- Data Cleaning and Type Conversion ---
    df_forces.columns = df_forces.columns.str.strip()
    df_connectivity.columns = df_connectivity.columns.str.strip()
    df_points.columns = df_points.columns.str.strip()
    for col in ['P', 'V2', 'V3', 'T', 'M2', 'M3', 'Station']: df_forces[col] = pd.to_numeric(df_forces[col], errors='coerce')
    for col in ['Length', 'Unique Name', 'UniquePtI', 'UniquePtJ']: df_connectivity[col] = pd.to_numeric(df_connectivity[col], errors='coerce')
    for col in ['UniqueName', 'X', 'Y', 'Z']: df_points[col] = pd.to_numeric(df_points[col], errors='coerce')
    df_forces.dropna(subset=['P', 'V2', 'V3', 'T', 'M2', 'M3', 'Station'], inplace=True)
    
    # --- Filter for allowed cases ---
    df_forces['Output Case'] = df_forces['Output Case'].str.strip()
    allowed_cases = ['Dead', 'Live', 'SDL', 'EX', 'EY']
    df_forces_filtered = df_forces[df_forces['Output Case'].isin(allowed_cases)]
    
    # --- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Combination ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥ ---
    df_combinations = calculate_combinations(df_forces_filtered)

    # --- <<<<<<<<<<<<<<< ‡∏à‡∏∏‡∏î‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà 1: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° df_merged_coords ‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡∏≤‡∏á >>>>>>>>>>>>>>> ---
    df_conn_subset = df_connectivity[['Unique Name', 'UniquePtI', 'UniquePtJ', 'Length']]
    df_points_coords = df_points[['UniqueName', 'X', 'Y', 'Z']].drop_duplicates(subset=['UniqueName'])
    df_merged_coords = pd.merge(df_conn_subset, df_points_coords, left_on='UniquePtI', right_on='UniqueName', how='left').rename(columns={'Z': 'UniquePtI_Z'}).drop(columns=['UniqueName', 'X', 'Y'])
    df_merged_coords = pd.merge(df_merged_coords, df_points_coords, left_on='UniquePtJ', right_on='UniqueName', how='left').rename(columns={'X': 'X', 'Y': 'Y', 'Z': 'UniquePtJ_Z'}).drop(columns=['UniqueName'])
    
    # --- ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥‡∏Å‡∏±‡∏ö‡∏û‡∏¥‡∏Å‡∏±‡∏î ---
    df_final = pd.merge(df_combinations, df_merged_coords, on='Unique Name', how='left')
    df_final.dropna(subset=['Station', 'Length', 'UniquePtI_Z', 'UniquePtJ_Z'], inplace=True)
    df_final = df_final[df_final['Length'] > 0].copy()
    df_final['Z_true'] = df_final['UniquePtI_Z'] + (df_final['Station'] / df_final['Length']) * (df_final['UniquePtJ_Z'] - df_final['UniquePtI_Z'])
    
    final_cols = ['Story', 'Column', 'Unique Name', 'Output Case', 'Station', 'P', 'V2', 'V3', 'T', 'M2', 'M3', 'X', 'Y', 'Z_true']
    return df_final[final_cols], df_forces_filtered, df_merged_coords

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö (Streamlit UI) ---
st.title("üèóÔ∏è Column Force Map Generator")

# --- Sidebar Controls ---
with st.sidebar:
    st.header("‚öôÔ∏è Controls")
    excel_file = st.file_uploader("1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel (.xlsx)", type="xlsx")

    if excel_file:
        if 'initial_data_processed' not in st.session_state or st.session_state.excel_file_name != excel_file.name:
            # --- <<<<<<<<<<<<<<< ‡∏à‡∏∏‡∏î‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà 2: ‡∏£‡∏±‡∏ö df_coords_map ‡∏°‡∏≤‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô session_state >>>>>>>>>>>>>>> ---
            st.session_state.df_base_result, st.session_state.df_raw_forces, st.session_state.df_coords_map = process_excel_data(excel_file)
            st.session_state.excel_file_name = excel_file.name
            st.session_state.initial_data_processed = True
            st.session_state.processed_df = st.session_state.df_base_result.copy() if st.session_state.df_base_result is not None else None

        if st.session_state.processed_df is not None:
            st.success("‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
            st.divider()

            with st.expander("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô (Underground)"):
                calc_ug = st.checkbox("‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô")
                if calc_ug:
                    stories = sorted(st.session_state.df_raw_forces['Story'].unique())
                    base_story = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:", options=stories)
                    st.write("‡∏Å‡∏£‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏Ñ‡∏π‡∏ì (Factor) ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:")
                    col1, col2, col3 = st.columns(3)
                    factor_dead = col1.number_input("Factor for Dead", value=1.0)
                    factor_sdl = col2.number_input("Factor for SDL", value=1.0)
                    factor_live = col3.number_input("Factor for Live", value=1.0)

                    if st.button("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô", type="primary"):
                        with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô... ‚è≥'):
                            base_floor_df = st.session_state.df_raw_forces[st.session_state.df_raw_forces['Story'] == base_story].copy()
                            value_cols_ug = ['P', 'V2', 'V3', 'T', 'M2', 'M3']
                            factors_map = {'Dead': factor_dead, 'SDL': factor_sdl, 'Live': factor_live}
                            dfs_to_combine = []
                            unmodified_mask = ~base_floor_df['Output Case'].isin(factors_map.keys())
                            dfs_to_combine.append(base_floor_df[unmodified_mask])
                            for case, factor in factors_map.items():
                                if factor != 1.0:
                                    mask = base_floor_df['Output Case'] == case
                                    if mask.any():
                                        modified_part = base_floor_df[mask].copy()
                                        modified_part[value_cols_ug] *= factor
                                        dfs_to_combine.append(modified_part)
                                else: # Factor is 1.0
                                    dfs_to_combine.append(base_floor_df[base_floor_df['Output Case'] == case])
                            
                            ug_df_raw = pd.concat(dfs_to_combine, ignore_index=True)
                            ug_df_raw['Story'] = "Underground"
                            ug_combinations_df = calculate_combinations(ug_df_raw)
                            
                            # --- <<<<<<<<<<<<<<< ‡∏à‡∏∏‡∏î‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà 3: Merge ‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô‡∏Å‡∏±‡∏ö‡∏û‡∏¥‡∏Å‡∏±‡∏î! >>>>>>>>>>>>>>> ---
                            # ‡∏ô‡∏≥‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô‡∏°‡∏≤ Merge ‡∏Å‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ
                            ug_final_df = pd.merge(ug_combinations_df, st.session_state.df_coords_map, on='Unique Name', how='left')
                            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Z_true ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô
                            ug_final_df.dropna(subset=['Station', 'Length', 'UniquePtI_Z', 'UniquePtJ_Z'], inplace=True)
                            ug_final_df = ug_final_df[ug_final_df['Length'] > 0].copy()
                            ug_final_df['Z_true'] = ug_final_df['UniquePtI_Z'] + (ug_final_df['Station'] / ug_final_df['Length']) * (ug_final_df['UniquePtJ_Z'] - ug_final_df['UniquePtI_Z'])
                            
                            # ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏±‡∏Å
                            st.session_state.processed_df = pd.concat([st.session_state.df_base_result, ug_final_df], ignore_index=True)
                            st.success("‚úîÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß!")
                            st.rerun()

                if st.button("‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï (‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥)"):
                    st.session_state.processed_df = st.session_state.df_base_result.copy()
                    st.info("‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß")
                    st.rerun()
            st.divider()

            # --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á Sidebar (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
            processed_df = st.session_state.processed_df
            with st.expander("‡∏î‡∏π‡πÅ‡∏•‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
                st.dataframe(processed_df)
                st.download_button(label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", data=convert_df_to_csv(processed_df), file_name='column_processed_results.csv', mime='text/csv')
            st.divider()
            story_list = sorted(processed_df['Story'].unique(), key=lambda x: (x != 'Underground', str(x)), reverse=True)
            if 'story' not in st.session_state or st.session_state.story not in story_list: st.session_state.story = story_list[0]
            st.subheader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏±‡πâ‡∏ô")
            st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á:", options=story_list, key='story')
            # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...

# --- Main Panel Display (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î) ---
if not excel_file:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á (Sidebar) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
elif 'processed_df' in st.session_state and st.session_state.processed_df is not None:
    processed_df = st.session_state.processed_df
    selected_story = st.session_state.story
    # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î) ...
    st.header(f"üó∫Ô∏è ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô: {selected_story}")
    # ... (‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
